# New Chapter: Spatial Data Structures (see modified chapters)

## Introduction
- here, we could discuss the importance of spatial data structures in geoinformatics and related fields.
-  Highlight the difference between traditional data structures and spatial data structures.
- Note that: This Chapter could end quite big?
- **For the spatial chapters https://cran.r-project.org/web/packages/spData/index.html will be quite handy for practical use, which is actively developed on! - maybe even for De_MSc_GeoStat something to use!** 

--- Just a Test Writing How the intro and Vector Data Structures might look like:

In the realm of geoinformatics, spatial data stands as a cornerstone, offering a lens through which we can view, analyze, and interpret the world around us. At this point in your Master's, you are already familiar with the basic spatial entities of: points, lines, and polygons. Perhaps you've encountered them in theoretical discussions or even visualized them using tools like ArcGIS Pro. These fundamental structures, while simple in concept, form the bedrock of complex spatial analyses and visualizations.

However, while the theoretical understanding of these structures is crucial, the real magic unfolds when we transition from theory to application. In this chapter, we're shifting our focus from merely recognizing these structures to actively manipulating and analyzing them using R.

R, with its rich ecosystem of packages, offers a unique perspective on spatial data. Packages like **sf** (which we already used in the previous chapters), **terra**, **stars**, and **spatstat** have been game-changers, allowing us to handle spatial data with unprecedented ease and flexibility. But before diving into these tools, it's essential to revisit the basics, not just as isolated concepts but as foundational blocks that will support our journey into spatial data application in R.

So, as we embark on this exploration, let's approach it as a bridge between what we know and what we're about to discover. We'll reconnect with familiar concepts, but with a fresh perspective, aiming to harness the full potential of spatial data structures in R.

## Fundamentals of Spatial Data Structures
### Vector Data Structures:
- Basic introduction
- Points: Basic units in space.
- Lines: Sequences of points.
- Polygons: Closed lines with associated areas.

Spatial data structures are the foundation upon which geospatial information is built. They provide a systematic framework for organizing and representing geographical entities, ensuring that they can be efficiently processed, analyzed, and visualized. In this section, we'll delve into vector data structures, which are essential for representing discrete spatial entities.

Vector data structures revolve around three primary entities: points, lines, and polygons. These might seem rudimentary, but their ability to represent real-world features is unparalleled. Let's explore each of these in detail:

#### Points:
Points are fundamental in geospatial analysis. They are the simplest spatial entities, representing a singular location in space. They have no dimensions, meaning they don't possess length, width, or area. Using the sf package, you can create and manipulate point data with ease:

```{r, echo=FALSE, message=FALSE}
library(sf)
library(terra)
```

```{r}
# Create a point
point <- st_point(c(5, 5))

# Convert to spatial feature
point_sf <- st_sf(geometry = st_sfc(point))

# Plot the point
plot(point_sf)

```

#### Lines:
Lines are sequences of points. They're instrumental in representing pathways, routes, or any linear feature. Here's how you can represent a line using sf:

```{r}
# Create a line from a matrix of coordinates
line <- st_linestring(matrix(1:6, 3, 2))

# Convert to spatial feature
line_sf <- st_sf(geometry = st_sfc(line))

# Plot the line
plot(line_sf)

```

#### Polygons:
Polygons are closed shapes, perfect for representing areas with defined boundaries. Here's a demonstration using sf and its st_polygon function:

```{r}

# Create a matrix of coordinates
coords <- matrix(c(2,2, 4,4, 4,2, 2,2), ncol = 2, byrow = TRUE)

# Create a list of matrices (in this case, just one matrix)
list_of_coords <- list(coords)

# Create the polygon
polygon <- st_polygon(list_of_coords)

# Convert to spatial feature
polygon_sf <- st_sf(geometry = st_sfc(polygon))

# Plot the polygon
plot(polygon_sf)
```

#### Quiz: Understanding Spatial Data Integrity

The code above successfully creates and plots a polygon. However, imagine if the last coordinate in the coords matrix was mistakenly omitted, leading to an error...

Consider following Questions:

1. What error would you expect to encounter if the last coordinate was omitted?
2. Why is the last coordinate crucial for the creation of the polygon?

<details>
<summary>Solution:</summary>

1. If the last coordinate was omitted, you would encounter the following error:

`Error in MtrxSet(x, dim, type = "POLYGON", needClosed = TRUE) : polygons not (all) closed`

  A breakdown of what the error message is conveying:
  
  - `MtrxSet(x, dim, type = "POLYGON", needClosed = TRUE)`: This is the internal function being called to set or validate the matrix representation of the polygon.
  
  - `type = "POLYGON"`: This indicates that the data structure being worked on is in fact a Polygon.
  
  - `needClosed = TRUE`: This is a condition set within the function to ensure that polygons are closed. It checks if the starting and ending coordinates of the polygon are the same.
  
  - `polygons not (all) closed`: This is the main error message, indicating that one or more polygons in your data are not closed, i.e., their starting and ending coordinates don't match.

In practical terms, if you're creating or manipulating polygons, you need to ensure that each polygon's last coordinate is the same as its first coordinate. If not, many spatial operations, analyses, or visualizations might produce incorrect or unexpected results!

2. The last coordinate is crucial because it ensures that the polygon is closed, meaning its starting and ending coordinates are the same.


</details>


```{block2, type = 'rmdtip'}
**Why did we not use Terra instead of sf?:**
While `sf` is predominantly used for vector data structures like points, lines, and polygons, `terra` is more oriented towards raster data. However, both packages can handle both vector and raster data to some extent. For vector operations, especially with points, lines, and polygons, `sf` is the preferred choice due to its comprehensive toolset and integration with the tidyverse ecosystem.
```

--- Just a Test on how to write..

- Then we could go into for example:

### Raster Data Structures:

- Grids: Regularly spaced cells.
- Pixels: The smallest non-divisible units in raster data.
- continous vs. discrete.. 

## Representing Spatial Data Structures in R
### Simple Features with sf:
- How sf represents vector data structures.
- sf objects and their components.
- Maybe even a "food for thought", WHY we use "sf" a lot.
- (Now, after we did the basics, get a bit deeper: Advanced operations with sf such as coordinate transformations (altough, this would fit very nicely in chapter 11 - see first), geometric operations, and spatial aggregations.)

## Raster Data with terra:
- Now, we consinder how terra represents raster data structures.
- Differences between terra and older packages like raster. **Information: (I actually think.. that's a good idea, because even though, we didn't cover raster. A lot of sources have used raster in the past, just to outline, that it was his predecessor) ?**
- dive deeper: Advanced raster operations, raster-vector conversions, and raster algebra with** terra** and intro to **stars**?

---for example:
## Raster Data with Terra
- Why Terra Over Older Packages like Raster?
While many older resources may use the raster package, terra is its modern successor, offering several advantages:

- Efficiency: Terra is optimized for speed and uses less memory, making it more efficient for large datasets.
- Flexibility: It supports raster, vector, and time-series data, providing a one-stop solution for various spatial data types.
- Ease of Use: With a simplified and consistent syntax, terra is easier to pick up for newcomers.
- Comprehensive Functions: From raster algebra to resampling and reclassification, terra offers a wide array of functionalities.
- Integration: It's designed to work seamlessly with other R packages, making it easier to integrate into larger workflows.


### Reading Raster Data
```{r}
# Load the terra package
library(terra)

# use the elevation tif file from "spData"
# "The raster data represents elevation in meters and uses WGS84 as a coordinate reference system."
elev <- system.file("raster/elev.tif", package = "spData")
elev <- rast(elev)
elev 

plot(elev) 
```
Once you've read the raster data, you can explore its properties using various functions:

- ncol(r): Number of columns
- nrow(r): Number of rows
- res(r): Resolution (pixel size)
- crs(r): Coordinate Reference System

### Basic Raster Operations
#### Cropping:
What is Raster Cropping?
Raster cropping is the process of selecting a specific area (or "extent") from a larger raster dataset. This is useful when you want to focus your analysis on a particular region.

Why Do We Need to Check the Original Raster's Extent?
Before cropping, it's crucial to know the extent of the original raster. This ensures that the area you want to crop actually exists within the original raster. If the extents don't overlap, you'll get an error.

How to Check the Extent?
You can use the ext() function from the terra package to check the extent of a raster.

```{r}
# Check the extent of the original raster
ext(elev)
```
- How to Crop?
Once you know the extent, you can specify a new extent within that range for cropping.

```{r}
# Define a new extent that is within the original raster's extent
crop_extent <- ext(-1, 1, -1, 1)  # These coordinates are within the original extent

# Crop the raster
elev_cropped <- crop(elev, crop_extent)
elev_cropped

```
### Common Pitfalls
- Non-overlapping Extents: Make sure the cropping extent overlaps with the original raster's extent, otherwise, you'll get an error.
- Coordinate Systems: Ensure that the raster and the extent are in the same coordinate system!


### Resampling Raster Data in Terra
#### What is Resampling?
Resampling is the process of changing the spatial resolution of a raster dataset. This is useful when you want to align multiple rasters that have different resolutions or when you want to change the level of detail in your analysis.

Step 1: Check the Original Resolution
Before resampling, it's important to know the original resolution of your raster. You can use the res() function to check this.

```{r}

res(elev) # shows us the resolution of 0.5. 0.5
plot(elev)
```
Where res is the new resolution.

Step 2: Choose a New Resolution
Decide what the new resolution should be. This could be higher or lower than the original, depending on your needs.
```{r}
# Resample the raster to the new resolution
new_res <- c(0.5, 0.5)  # Example new resolution, for example double the size.

```
Step 3: Perform Resampling
You can use the resample() function to change the resolution. The method can be "nearest", "bilinear", etc., depending on the type of interpolation you want to use.

```{r}

elev_resampled <- resample(elev, new_res, method="bilinear")
# Create a target raster with the new resolution
target_raster <- rast(elev, res=new_res)
# Resample the original raster to match the target raster
elev_resampled <- resample(elev, target_raster, method="bilinear")
# Check the new resolution
res(elev_resampled)

```

Masking: To mask a raster using another raster or vector, you can use the mask() function.

```{r}
r_masked <- mask(r, mask_layer)
```
Where mask_layer is another raster or a vector layer

---

## Multidimensional Data with stars:
- Introduction to stars and its capability to handle multidimensional arrays.
- How stars complements **sf** and **terra** in the R spatial ecosystem.
- Dive Deeper: Handling time series, three-dimensional data, and other multidimensional datasets with **stars**.

## Spatial Indexing
- Introduction to spatial indexing and its importance.
- Would be pretty Important (Atleast, of what I would see it as.)
- Common spatial indexing techniques:
- Quadtree
- R-tree
- KD-tree
- How spatial indexing is implemented in R packages.
- Dive Deeper: Performance benefits of spatial indexing and real-world use cases.

## Topological Relationships
- Discuss spatial relationships like:
- Adjacency (what's next to what)
- Connectivity (how things are connected)
- Containment (what contains what)
- Importance of understanding topological relationships in spatial analysis and how one might implement that in R.

## Introduction to spatstat for point pattern analysis.(**!!! not recommended.. would be beneficial for Chapter 12.**)
- Maybe even as a bridge to "Spatial Statistics Module"? - **altough, that could also be a big one in chapter 12 see ( Applied Spatial Statistics with spatstat)**
- Dive Deeper: Advanced topological operations and their applications in spatial analysis using **spatstat**.

## Practical Applications and Exercises
Exercises focusing on understanding spatial data structures in R, leveraging the capabilities of **sf**, **terra**, **stars**, and **spatstat**... altough, this might be a bit too much and should be lowered.. 
